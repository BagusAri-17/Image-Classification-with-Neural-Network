#!/usr/bin/env python
# coding: utf-8

# In[1]:


import os
from skimage import data, io, feature, util, transform
import numpy as np
from matplotlib import pyplot as plt
import pandas as pd


# ## Image Extraction

# In[2]:


happy = os.listdir(f'Happy/')
sad = os.listdir(f'Sad/')

happy = ['Happy/' + i for i in happy]
sad = ['Sad/' + i for i in sad]

happy = np.array([io.imread(i, as_gray=True) for i in happy])
sad = np.array([io.imread(i, as_gray=True) for i in sad])


# ## Process Image to Dataframe

# In[3]:


features = ['dissimilarity', 'correlation', 'homogeneity', 'contrast', 'ASM', 'energy']
angle = [0, 45, 90, 135, 180]

df = {}

for i in features:
    for j in angle:

        df[i.capitalize() + str(j)] = np.array([])

df['Label'] = np.array([])

for i in happy:
    
    for j in range(len(features)):

        a = feature.graycomatrix(i, distances=[1], angles=angle, levels=256,
                            symmetric=True, normed=True)
        a = feature.graycoprops(a, prop=features[j]).flatten()
        
        for k in range(len(angle)):

            df[features[j].capitalize() + str(angle[k])] = np.append(a[k], df[features[j].capitalize() + str(angle[k])])
    df['Label'] = np.append('Happy', df['Label'])

for i in sad:
    
    for j in range(len(features)):
        
        a = feature.graycomatrix(i, distances=[2], angles=angle, levels=256,
                            symmetric=True, normed=True)
        a = feature.graycoprops(a, prop=features[j]).flatten()
        
        for k in range(len(angle)):

            df[features[j].capitalize() + str(angle[k])] = np.append(a[k], df[features[j].capitalize() + str(angle[k])])
    df['Label'] = np.append('Sad', df['Label'])

df = pd.DataFrame(df)


# ## Make Preprocessing Function pt. 1

# In[4]:


def preprocessing_1(photo_dir):
    
    from skimage import data, io, feature, util, transform
    import numpy as np
    
    features = ['dissimilarity', 'correlation', 'homogeneity', 'contrast', 'ASM', 'energy']
    angle = [0, 45, 90, 135, 180]

    res = np.array([])
    
    for j in features:
        
        a = feature.graycomatrix(photo_dir, distances=[2], angles=angle, levels=256,
                            symmetric=True, normed=True)
        a = feature.graycoprops(a, prop=features[j]).flatten()

        for k in range(len(angle)):

            res = np.append(a[k], res)
    
    return res


# ## Make Train and Test Data

# In[5]:


from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler

X, y = df.drop(columns=['Label']), df['Label']
sc =  StandardScaler()
X = sc.fit_transform(X)
le = LabelEncoder()
y = le.fit_transform(y)
X_train, X_test, y_train, y_test = train_test_split(X, y,
                                                    test_size=0.25,
                                                    random_state=0)


# In[6]:


df.head()


# ## Make Neural Network Model

# In[7]:


from tensorflow.keras import Sequential, layers

model = Sequential([
    layers.Dense(30, activation='relu'),
    layers.Dense(256, activation='relu'),
    layers.Dense(512, activation='relu'),
    layers.Dense(1024, activation='relu'),
    layers.Dropout(0.25),
    layers.Dense(1024, activation='relu'),
    layers.Dense(512, activation='relu'),
    layers.Dense(256, activation='relu'),
    layers.Dense(2, activation='sigmoid')
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])


# In[8]:


model.fit(X_train, y_train, epochs=50)


# ## Evaluate The Model

# In[9]:


model.evaluate(X_test, y_test)


# In[10]:


from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
y_pred = model.predict(X_test)
y_predi = y_pred[:, 0] < y_pred[:, 1]
for i in range(len(y_predi)):
    y_predi[i] = int(y_predi[i])
        
score = {'Accuracy':accuracy_score(y_test, y_predi),
         'Precision':precision_score(y_test, y_predi, average=None),
         'Recall':recall_score(y_test, y_predi, average=None),
         'F1':f1_score(y_test, y_predi, average=None),
         }
pd.DataFrame(score)


# In[11]:


avg = {'Accuracy':[pd.DataFrame(score)['Accuracy'].mean()],
       'Precision':[pd.DataFrame(score)['Precision'].mean()],
       'Recall':[pd.DataFrame(score)['Recall'].mean()],
       'F1':[pd.DataFrame(score)['F1'].mean()]}

pd.DataFrame(avg)


# In[12]:


X_train[0].shape


# ## Save Preprocessing and Model into .pkl Extension

# In[13]:


model.summary()


# In[14]:


from pickle import dump
dump(model, open('model.pkl', 'wb'))
dump(sc, open('scaling.pkl', 'wb'))
dump(le, open('label.pkl', 'wb'))


# In[40]:


model.predict(np.array(sc.transform(np.array([df.drop(columns=['Label']).iloc[3]]))))

